import requests
import time
import random
from bs4 import BeautifulSoup
from utils.mongoUtils import connect_exploit
from spider_utils import user_agent_pc, get_proxy, random_sleep

'''截止2021-09-26 exploit-db 共50331条数据'''
coll = connect_exploit()
def exp_spider():
    count = 0
    base = 'https://www.exploit-db.com/exploits/'
    headers = {
        'User-Agent': random.choice(user_agent_pc)
    }
    proxy = get_proxy().get("proxy")
    exp_id = 470
    print()
    while (exp_id <= 50440):
        url = base + str(exp_id)
        # 访问被禁止后，更换代理
        try:
            res = requests.get(url, headers=headers, proxies={"http": "http://{}".format(proxy)})
        except Exception as e:
            print(e)
            print("第{}次更换代理...".format(count))
            count += 1
            proxy = get_proxy().get("proxy")
            res = requests.get(url, headers=headers, proxies={"http": "http://{}".format(proxy)})
        soup = BeautifulSoup(res.text,features="lxml")
        exp = {}
        exp['title'] = soup.title.string
        for div in soup.find_all('div', class_='col-sm-12 col-md-6 col-lg-3 d-flex align-items-stretch'):
            for h in div.find_all('div', class_='col-6 text-center'):
                if h.h4.get_text().strip() == 'EDB-ID:' :
                    exp['edb_id'] = h.h6.get_text().strip()
                if h.h4.get_text().strip() == 'CVE:' :
                    exp['cve'] = h.h6.get_text().strip()
                if h.h4.get_text().strip() == 'Author:' :
                    exp['author'] = h.h6.get_text().strip()
                if h.h4.get_text().strip() == 'Type:' :
                    exp['type'] = h.h6.get_text().strip()
                if h.h4.get_text().strip() == 'Platform:' :
                    exp['plat'] = h.h6.get_text().strip()
                if h.h4.get_text().strip() == 'Date:' :
                    exp['date'] = h.h6.get_text().strip()
            for s in div.find_all('div', class_='stats h5 text-center'):
                if s.strong.string.strip() == 'EDB Verified:':
                    if s.i['class'] == ['mdi', 'mdi-24px', 'mdi-check']:
                        exp['verified'] = 'Yes'
                    else:
                        exp['verified'] = 'No'
                elif s.strong.string.strip() == 'Exploit:':
                    exp['code'] = base + s.a['href']
                else:
                    if s.find('a'):
                        exp['app'] = base + s.a['href']
        print(exp_id)
        if exp['title'] != '404 Page Not Found | Exploit Database':
            coll.insert_one(exp)
        random_sleep()
        exp_id += 1

if __name__ == '__main__':
    exp_spider()